# 201-ai-openwebui.yaml
#
# Description:
# Helm values for deploying Open WebUI in the 'ai' namespace with PostgreSQL/pgvector for vector storage, Tika for document extraction, Ollama integration, and Okta OIDC SSO. This configuration is designed for production-like environments with persistent storage and externalized secrets.
#
# Components:
# - Open WebUI: Main chat and document interface
# - PostgreSQL/pgvector: Vector database for RAG and embeddings (no Qdrant)
# - Tika: Document extraction (enabled and managed by Helm)
# - Ollama: External LLM inference (native Mac or cluster)
# - Okta OIDC SSO: Single Sign-On via OpenID Connect (secrets managed in urbalurba-secrets)
#
# Features:
# - Uses existing PVC for persistent data storage
# - All sensitive values (secrets, admin email, etc.) are referenced from the 'urbalurba-secrets' secret
# - No Redis or WebSocket support enabled (not required for standard chat and RAG)
# - Ingress is managed separately (not enabled here)
#
# Usage:
# helm upgrade --install open-webui open-webui/open-webui -f manifests/201-ai-openwebui.yaml -n ai
#
# Notes:
# - Enable Redis and WebSocket only if you need real-time collaborative chat or streaming updates.
# - Tika is now managed by the Helm chart; standalone Tika deployment is not required.
#
# Namespace: ai

ollama:
  enabled: false

ollamaUrls:
  - "http://host.lima.internal:11434"

pipelines:
  enabled: true

tika:
  enabled: true

websocket:
  enabled: false

redis-cluster:
  enabled: false

# Use existing PVC for persistence
persistence:
  enabled: true
  existingClaim: "openwebui-data"
  accessModes:
    - ReadWriteOnce
  size: 2Gi

namespace: ai

resources:
  requests:
    memory: 1.5Gi
    cpu: 500m
  limits:
    memory: 3Gi
    cpu: 1500m

extraEnvVars:
  # Database configuration
  - name: DATABASE_URL
    value: "postgresql://openwebui:openwebui@openwebui-db:5432/openwebui"
  - name: VECTOR_DB
    value: "pgvector"
  - name: PGVECTOR_DB_URL
    value: "postgresql://openwebui:openwebui@openwebui-db:5432/openwebui"

  # Ollama configuration
  - name: OLLAMA_BASE_URL
    value: "http://host.lima.internal:11434"

  # RAG configuration
  - name: CHUNK_SIZE
    value: "1000"
  - name: CHUNK_OVERLAP
    value: "200"
  - name: RAG_EMBEDDING_ENGINE
    value: "ollama"
  - name: RAG_EMBEDDING_MODEL
    value: "nomic-embed-text:latest"

  # Security
  - name: WEBUI_SECRET_KEY
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: WEBUI_SECRET_KEY

  # Admin configuration
  - name: ADMIN_EMAIL
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: ADMIN_EMAIL

  # OIDC/Okta SSO configuration
  - name: ENABLE_OAUTH_SIGNUP
    value: "true"
  - name: OAUTH_MERGE_ACCOUNTS_BY_EMAIL
    value: "true"
  - name: OAUTH_PROVIDER_NAME
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: OAUTH_PROVIDER_NAME
  - name: OPENID_PROVIDER_URL
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: OPENID_PROVIDER_URL
  - name: OAUTH_CLIENT_ID
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: OAUTH_CLIENT_ID
  - name: OAUTH_CLIENT_SECRET
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: OAUTH_CLIENT_SECRET
  - name: OPENID_REDIRECT_URI
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: OPENID_REDIRECT_URI
  - name: OAUTH_SCOPES
    value: "openid email profile"

  # OpenAI configuration (optional)
  - name: OPENAI_API_KEY
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: OPENAI_API_KEY

podLabels:
  app: "open-webui"

service:
  type: ClusterIP
  port: 8080

ingress:
  enabled: false  # Use a separate ingress manifest if needed 