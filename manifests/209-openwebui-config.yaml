# 209-openwebui-config.yaml
# 
# Description:
# Open WebUI configuration with direct connections to Ollama instances:
# 1. Host Ollama: Direct connection to Ollama running on the host machine (Mac with M2 CPU)
#    - Allows downloading and managing models directly through the UI
#    - No config changes needed to use new models downloaded to host
# 2. In-Cluster Ollama: Direct connection to Ollama running in the Kubernetes cluster
#    - Access to the qwen3:0.6b model deployed in the cluster
#
# This configuration maintains compatibility with existing Tika and Qdrant integrations
# The helm doc is here https://github.com/open-webui/helm-charts/tree/main/charts/open-webui
# 
# Usage:
# installing: helm install open-webui open-webui/open-webui -f 209-openwebui-config.yaml -n ai
# upgrading:  helm upgrade open-webui open-webui/open-webui -f 209-openwebui-config.yaml -n ai
# uninstalling: helm uninstall open-webui -n ai
#
# Prerequisites:
# - Ollama must be running in the AI namespace configured with 205-ollama-config.yaml
# - The 'urbalurba-secrets' secret must exist in the AI namespace with required API keys
# - Tika should be set up in a separate pod in the AI namespace
# - Qdrant should be running for vector database storage
# - Ollama should be running on the host machine (Mac with M2 CPU)


# Disable the embedded Ollama since we're using external Ollama instances
ollama:
  enabled: false

# Sets up link to the ollama running in the cluster and the ollama running on the host (same as using the OLLAMA_BASE_URLS)
ollamaUrls:
  - "http://ollama:11434"
  - "http://host.lima.internal:11434"    
#dor docker  - "http://host.docker.internal:11434"  

# Enable Pipelines for document processing
pipelines:
  enabled: true

# Disable websocket (would require Redis)
websocket:
  enabled: false

# Disable Redis cluster
redis-cluster:
  enabled: false
  
# Disable the built-in Tika since we're using a standalone deployment
tika:
  enabled: false

# Persistent storage for Open WebUI
persistence:
  enabled: true
  existingClaim: "openwebui-data"
  accessModes:
    - ReadWriteOnce
  size: 2Gi  # Size still defined but won't be used when existingClaim is set
  
# Specify the namespace explicitly
namespace: ai

# Resources for Open WebUI
# Resource configuration based on observed real-world usage patterns:
# - CPU: Set to 1.5 cores (1500m) limit based on observed usage patterns
#   - Request set to 500m to ensure proper baseline performance
# - Memory: Set to 3Gi limit based on observed usage of 1530MB (~1.5Gi)
#   - Request set to 1.5Gi to match actual observed base usage
# These values provide:
# - 3x headroom for CPU spikes from baseline usage
# - 2x headroom for memory growth and stability
# - Sufficient resources for document processing, RAG operations, and model interactions
# - Protection against OOM (Out of Memory) termination
resources:
  requests:
    memory: 1.5Gi
    cpu: 500m
  limits:
    memory: 3Gi
    cpu: 1500m

# ===== Start: Host configuration for accessing Ollama on host =====
# This allows the pods to resolve host.docker.internal to the host machine
# Required for Rancher Desktop to properly connect to Ollama running on Mac host
extraHostAliases:
  - ip: "host-gateway"
    hostnames:
      - "host.docker.internal"
# ===== End: Host configuration for accessing Ollama on host =====





# Environment variables for connecting Open WebUI to Ollama instances and other services
extraEnvVars:
  # ===== Start: Ollama Connection Settings =====

  # Set the model that is downloaded in the cluster to be the default model.
  - name: DEFAULT_MODELS
    value: "qwen3:0.6b"

  # Enable model management features
  - name: ENABLE_MODEL_EXPLORATION 
    value: "true"
  - name: ENABLE_DYNAMIC_MODEL_LOADING
    value: "true"
  - name: ENABLE_OLLAMA_INTEGRATION
    value: "true"
  - name: OLLAMA_DIRECT_CONNECTION
    value: "true"
  # ===== End: Ollama Connection Settings =====


  # ===== Start: Authentication Settings =====
  # login using email is the default login
  - name: WEBUI_AUTH
    value: "true"
  
# subsequent users will be users
  - name: DEFAULT_USER_ROLE
    value: "user"
  # ===== End: Authentication Settings =====
  
  # ===== Document Processing Settings =====
  # Configure Open WebUI to use the standalone Tika server for document extraction
  - name: CONTENT_EXTRACTION_ENGINE
    value: "tika"
  - name: TIKA_SERVER_URL
    value: "http://tika:9998"
  
  # ===== Vector Database Settings =====
  # Configure Open WebUI to use Qdrant for vector storage
  - name: VECTOR_DB
    value: "qdrant"
  - name: QDRANT_URI
    value: "http://qdrant:6333"
  - name: QDRANT_API_KEY
    valueFrom:
      secretKeyRef:
        name: urbalurba-secrets
        key: OPENWEBUI_QDRANT_API_KEY
  - name: QDRANT_COLLECTION_NAME
    value: "openwebui_documents"
  
  # ===== Embedding Model Configuration =====
  # Current default model for RAG embeddings
  - name: RAG_EMBEDDING_MODEL
    value: "all-MiniLM-L6-v2"
  
  # Norwegian BERT model options (uncomment to use):
  # - name: RAG_EMBEDDING_MODEL
  #   value: "NorBERT"  # General purpose Norwegian BERT
  #   # Alternative options:
  #   # value: "NorBERT-3-Large"  # More powerful but larger model
  #   # value: "Klinisk-NorBERT"  # For medical/clinical text
  #   # value: "NB-BERT"  # For historical text support
  #   # value: "Norwegian-BERT"  # Community version
  #
  # - name: RAG_LANGUAGE
  #   value: "no"  # Norwegian language code
  #
  # - name: RAG_MODEL_PARAMS
  #   value: '{"model_type": "norwegian-bert", "max_length": 512}'
  
  # ===== Enhanced Features =====
  # Enhanced search capabilities
  - name: ENABLE_PARALLEL_SEARCH
    value: "true"
  - name: ENABLE_MULTI_THREADED_SEARCH
    value: "true"
  
  # Enhanced document processing
  - name: ENABLE_AUDIO_TRANSCRIPTION
    value: "true"
  - name: ENABLE_MARKDOWN_IMPORT
    value: "true"
  
  # Enhanced security features
  - name: ENABLE_AUDIT_LOGS
    value: "true"
  - name: ENABLE_ROLE_CONFIRMATION
    value: "true"
  
  # ===== Logging Configuration =====
  - name: RAG_LOG_LEVEL
    value: "INFO"

# Additional labels for network policies
podLabels:
  tika-client: "true"
  app: "open-webui"
  
# Service configuration
service:
  type: ClusterIP
  port: 8080

# Ingress configuration
# NOTE: Disabled here because there is a bug in the Helm chart.
# The actual ingress is defined in 210-openwebui-ingress.yaml and applied separately.
ingress:
  enabled: false
  # The following settings are not used but kept for reference
  className: "traefik"
  annotations:
    traefik.ingress.kubernetes.io/ssl-redirect: "false"
  hosts:
    - host: "openwebui.localhost"
      paths:
        - path: /
          pathType: Prefix